data:
  raw_csv: data/raw/delivery_reviews.csv
  text_col_candidates: ["review", "review_text", "text", "comment"]
  rating_col_candidates: ["rating", "stars", "score"]
  id_col_candidates: ["id", "row_id"]
  test_size: 0.2
  stratify_on_rating: true

cleaning:
  lowercase: true
  remove_stopwords: true
  lemmatize: true
  remove_punctuation: true


sentiment_from_rating:
  negative_max: 2
  neutral_min: 3
  neutral_max: 3
  positive_min: 4

random_seed: 42
transformer:
  model_name: "distilbert-base-uncased"
  max_length: 128
  batch_size: 16
  epochs: 3
  lr: 2e-5
  warmup_ratio: 0.1

data:
  raw_csv: data/raw/delivery_reviews.csv
  text_col_candidates: ["review", "review_text", "text", "comment"]
  rating_col_candidates: ["rating", "stars", "score"]
  id_col_candidates: ["id", "row_id"]
  test_size: 0.2
  stratify_on_rating: true

output:
  results_dir: data/processed
  models_dir: fast_delivery_ml_project/models
  figs_dir: fast_delivery_ml_project/figs
features:
  tfidf_max_features: 10000
  ngram_range: [1, 2]
  min_df: 2       # Could also be a float like 0.01 (1%)
  max_df: 0.95    # Must be > min_df



models:
  classical:
    logistic_regression:
      C: 1.0
      max_iter: 100
    random_forest:
      n_estimators: 100
      max_depth: 10
    svm:
      C: 1.0
      kernel: linear
    linear_svc:
      C: 1.0
    xgboost:
      max_depth: 6
      learning_rate: 0.1
      n_estimators: 100
      objective: multi:softprob
    lightgbm:
      num_leaves: 31
      learning_rate: 0.05
      n_estimators: 100

  regression:
    ridge:
      alpha: 1.0
      max_iter: 1000
    random_forest:
      n_estimators: 100
    xgboost:
      n_estimators: 100
      learning_rate: 0.1
      max_depth: 6
    lightgbm:
      n_estimators: 100
      learning_rate: 0.05
      num_leaves: 31




